{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d07a5eca-f07d-4465-8e95-b2b382774fab",
   "metadata": {},
   "source": [
    "I tried to just load the mhd files directly before doing any preprocessing, but then the kernel died after 21 images loaded, so I might have to do some preprocessing directly after loading the image and then saving that smaller array. When printing the shape of the ct scans I could also see that each slize was 512*512 but that a different number of slices was used for each ct scan, from 100 to 500, so it could differ quite a lot. I don´t know if the slice number has a certain significance. Looking at this article: https://soundvet.com/portable-ct/understanding-ct-scanner-specifications-slice-count-scan-speed-and-cost-efficiency/ it seems like a whole ct scanner might be set to a certain number of slices, but maybe there are scanners where you can adjust the number of slices? According to this article: https://lbnmedical.com/ct-scan-slice-types/ a CT scanner takes 4 - 640 slices. According to the article it seems like our ct scans with over 100 slices are very detailed, have very high image quality and have been taken with expensive machines - alright. I´m still a bit confused about the irregular number of slices, I would expect powers of 2, maybe 128,256 etc but I´m seeing 204, 157, 139 etc - maybe I´ll figure that one out later. \n",
    "\n",
    "Since we only need 20 images anyways for the training, maybe we can load just 20 imaged and train the model in this notebook. Then we can load the model from another notebook and do the validation there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "560aef2b-4eb6-4d6a-bbd5-c106ce81d299",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "#SimpleITK helps us load the mhd files into numpy arrays\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "local_path = '/home/ec2-user/SageMaker/images/'\n",
    "\n",
    "filenames_train = []\n",
    "for idx,filename in enumerate(glob.glob(os.path.join(local_path, '*.mhd'))):\n",
    "    filenames_train.append(filename)\n",
    "    if(idx == 19):\n",
    "        break\n",
    "\n",
    "print(len(filenames_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6322dd0e-2d26-407b-bb28-e5375aafb0ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_mhd_file(file_path):\n",
    "    # Read the MHD file using SimpleITK\n",
    "    image = sitk.ReadImage(file_path)\n",
    "    \n",
    "    # Convert it to a NumPy array (H x W x D)\n",
    "    image_array = sitk.GetArrayFromImage(image)\n",
    "    \n",
    "    return image_array\n",
    "\n",
    "image_arrays = []\n",
    "for filename in filenames_train:\n",
    "    image_data = load_mhd_file(filename)\n",
    "    image_arrays.append(image_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a612d685-34a6-4b49-8b56-9fea9760aa8a",
   "metadata": {
    "tags": []
   },
   "source": [
    "I found this tutorial for finetuning a U-net model on SageMaker Neo: https://sagemaker-examples.readthedocs.io/en/latest/sagemaker_neo_compilation_jobs/tensorflow_unet/sagemaker-neo-tf-unet.html\n",
    "\n",
    "I might need to do some changes to change it to using a 3D U-net model though. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
