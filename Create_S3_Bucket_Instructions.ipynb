{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an S3 bucket\n",
    "\n",
    "After preprocessing our data in our EC2 instance we are ready to create an S3 bucket where we can store this data. \n",
    "\n",
    "In the AWS console we search for S3 and click on \"Create Bucket\"\n",
    "\n",
    "We need to enter a unique name for our bucket - it must be globally unique across all of AWS\n",
    "\n",
    "We also add a region for where we want our bucket to reside\n",
    "\n",
    "I left the rest of the options as defaults \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading data to S3 from our jupyter notebook in our EC2 instance\n",
    "\n",
    "You can use the following command to upload something from your EC2 instance to your S3 bucket\n",
    "\n",
    "aws s3 cp /path/to/local/file s3://your-bucket-name/path/in/bucket/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assigning AWS credentials to the EC2 instance\n",
    "\n",
    "When running the above command to move data between EC2 and S3 you might runt into some problems related to not having the right credentials. E.g. a \"NoCredentialsError\". To fix this problem we can assign an IAM role to our EC2 instance. We go to the EC2 dashboard in our AWS console and click on actions, then security, and then modify IAM role. You might need to create a new IAM role. Chose AWS Service as the trusted entity. Chose EC2 as the service/use case. I attached \"AmazonS3FullAccess\" permission - so for uploading and downloading. I set the role name to EC2_access_S3. Now we can go back to the modify IAM role window and choose this new IAM role that we created. Our instance is now attached to this new IAM role. We can now go ahead an upload data from EC2 to S3. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
